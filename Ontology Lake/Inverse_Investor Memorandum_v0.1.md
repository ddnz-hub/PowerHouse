# **INVERSE**

# **Custodial Stewardship of Field-Native AI**

---

## **Pre-Seed Investor Memorandum**

### Contents

1. Deal Snapshot  
2. Executive Summary  
3. The Historic Threshold  
4. The Problem & Intervention  
5. The Technology: Field-Native AI  
6. Phase I: Governance Layer for AI Agents  
7. Market & Valuation  
8. Structural Separation  
9. Competition & Landscape  
10. Risk & Structural Mitigations  
11. Pre-Seed Round: Capital Structure & Use of Funds  
12. Capital Phases, On-Ramps, and Off-Ramps  
13. Closing Orientation  
14. Appendix A: Market Scope & Economic Underwriting  
15. Glossary

# **1\. Deal Snapshot**

Entity: Inverse  
Role: Custodial steward of capital, governance, and posture  
Technology Infrastructure: Field-Native AI  
Initial Product: Governance layer for AI agents (action gating & epistemic integrity)

## The Raise

* Round: Pre-Seed  
* Capital Value: USD $2.0M  
* Pre-Money Valuation: USD $40.0M  
* Equity Offered: 5.0%

### What This Capital Funds

* Phase I build of Field-Native AI: AI agent governance layer  
* Implementation of action-gating, provenance, and refusal constraints  
* Early institutional pilots in AI-native environments  
* Establishment of custodial governance structures

### What This Is — and Is Not

This is not an application startup.  
This is not a foundation model company.  
This is not a growth-optimised AI business.

This round places Inverse as the custodial steward of an infrastructure-grade intelligence substrate, with capital deployed into Field-Native AI under explicit constraints.

# **2\. Executive Summary**

Civilisation has crossed a threshold where orientation itself has become power.

As AI systems scale, decisions are increasingly executed:

* Without discernment before implication has been processed,  
* without verifiable authorship  
* and without a shared capacity to refuse action when uncertainty is present.

The result is beyond error or misalignment. It is a deeper failure: epistemic collapse under pressure

When intelligence systems cannot distinguish between:

* what leads  
* what follows,  
* what is assumed,  
* what is contradictory,  
* and where implication stops,

Urgency coerces authority to choose speed, fluency, and optimisation over discernment  
In this context responsibility is diffused and the way we address harm becomes retrospective instead of preventative.

# **3\. The Historic Threshold**

Civilisation has crossed a threshold at which **orientation itself has become power**.

For most of human history, the consequences of action were bounded by scale, time, and proximity. Decisions could be sensed, implications could be felt, and responsibility could be claimed before harm became irreversible.

That condition no longer holds.

Modern technological, economic, and institutional systems now act:

* at speeds that outpace human discernment,

* across scales that diffuse responsibility,

* and through abstractions that obscure causality.

As a result, decisions are increasingly made **before implication is visible**, and action proceeds without a shared capacity to determine whether it should occur at all.

This is not a failure of intelligence, intent, or ethics.  
 It is a failure of **orientation under scale**.

### **The Consequence of Scale Without Orientation**

When systems operate beyond the capacity to sense implication:

* optimisation replaces discernment,

* execution precedes responsibility,

* and correction becomes retrospective rather than preventative.

Once this threshold is crossed, downstream governance mechanisms — policy, compliance, and oversight — are structurally too late.

Harm is addressed only after it has already occurred.

### **Why This Moment Is Different**

What makes this threshold historic is not the presence of advanced technology alone, but the convergence of:

* autonomous systems capable of irreversible action,

* capital flows that accelerate execution without accountability, and

* institutional decision-making detached from felt consequence.

At this point, the absence of a shared, verifiable way to orient to reality **before action** becomes a systemic risk.

### **What This Makes Necessary**

Beyond this threshold, civilisation requires infrastructure that can:

* surface implication before execution,

* preserve uncertainty without collapse,

* and allow responsibility to be claimed upstream rather than assigned after harm.

This requirement is structural, not ideological.

It is the condition that makes custodial intervention necessary.

## **4\. The Problem & Intervention**

**The problem is simple:**

*“Modern systems act before implication is visible, leaving no shared, verifiable way to determine whether action should occur at all.”*

Inverse exists to provide a custodial intervention at this historic threshold.

Its role is to steward capital, governance, and posture into Field-Native AI — a technology infrastructure designed to restore shared, verifiable orientation, making discernment standardised and feasible before action.

Inverse does not exist to optimise execution.  
It operates upstream of execution to ensure that action cannot occur without epistemic integrity.

# **5\. The Technology: Field-Native AI**

Field-Native AI is an orientation-first intelligence substrate built on a foundational inversion of how intelligence is framed today:

Intelligence is not the production of answers.  
Intelligence is the faithful unfolding of implication under declared frames.

Rather than optimising for prediction or reward, Field-Native AI computes entailment surfaces that explicitly preserve:

* provenance  
* boundary  
* contradiction  
* uncertainty

As a result, action is no longer assumed.  
It becomes optional and gated, because the technology makes a new epistemic state visible:

Implication \- the inverse of inference.

# 

# **6\. Phase I: Governance Layer for AI Agents**

### **Why This Is the First Wedge**

The initial deployment of Field-Native AI is a **governance layer for AI agents operating on existing models**.

This wedge is chosen deliberately.

AI agents already:

* operate autonomously,  
* take irreversible actions,  
* and act under time and optimisation pressure.

What they lack is not capability, but **verifiable orientation before execution**.

Field-Native AI intervenes precisely at this gap, upstream of action, downstream of sensing, without requiring replacement of existing models or systems.

### **What the Governance Layer Does**

The governance layer provides a **pre-action epistemic substrate** that sits between AI agents and execution environments.

It performs three core functions:

1. **Frame Declaration**  
   All agent actions are evaluated under explicit frames that define:  
   * authority,  
   * admissible assumptions,  
   * temporal semantics,  
   * and scope of permission.  
2. **Entailment & Boundary Computation**  
   Before action is permitted, the system computes an entailment surface that makes explicit:  
   * what follows from available claims,  
   * where implication stops,  
   * where contradiction exists,  
   * and what remains undecidable.  
3. **Action Gating or Refusal**  
   If implication is incomplete or contradictory under the declared frame:  
   * action is withheld,  
   * refusal is explicit,  
   * and provenance is preserved for audit.

Non-action is treated as a valid and often correct outcome.

### **What This Prevents**

This layer structurally prevents failure modes that currently scale with AI capability, including:

* hallucinated authority  
* execution under hidden assumptions  
* silent collapse of uncertainty  
* unowned implication and responsibility  
* post hoc rationalisation of harm

These failures cannot be reliably addressed through alignment, monitoring, or policy alone, because they occur **before outputs are produced**.

### **How It Integrates**

The governance layer is **model-agnostic** and integrates alongside existing systems.

* It does not replace LLMs or agents  
* It does not generate decisions  
* It does not optimise outcomes

It constrains execution by restoring epistemic integrity.

Deployment occurs:

* as a middleware layer,  
* via APIs and execution hooks,  
* and through explicit refusal pathways.

This allows for early adoption without re-architecting existing stacks.

### **Initial Buyers and Adoption Path**

Phase I buyers are institutions already exposed to:

* autonomous agent risk,  
* regulatory scrutiny,  
* or post-incident liability.

Initial adopters include:

* AI-native organisations deploying autonomous agents,  
* regulated industries experimenting with agent execution,  
* and public or quasi-public entities requiring auditability.

Adoption follows a deliberate path:

1. Pilot deployment on bounded agent scopes  
2. Validation through refusal and audit events  
3. Expansion to broader agent classes

Trust accumulates through **what the system refuses to do**, not what it accelerates.

### **Commercial Model (Phase I)**

Revenue is derived from:

* platform licensing for the governance layer,  
* domain-specific deployment modules,  
* and bounded custodial services where appropriate.

Pricing reflects:

* institutional value,  
* high-stakes risk mitigation,  
* and infrastructure-grade dependency.

This is not usage-based optimisation software. It is governance infrastructure.

### **Why This Generalises**

If Field-Native AI can:

* gate action,  
* preserve implication,  
* and remain coherent

In AI agent environments  where speed, autonomy, and pressure are extreme, the same architecture generalises to other domains without change in principle.

Phase I is not a niche application as we are seeking **proof of infrastructural validity**.

### **Why Now**

AI capability has outpaced the structures required to govern its consequences.

Regulation, alignment, and monitoring efforts all operate **downstream of decisions already made**.

Once implication is lost, no amount of policy can restore it.

The next decade will not be defined by who builds the most powerful models, but by who establishes the **conditions under which power can be exercised legitimately**.

## **7\. Market & Valuation**

Field-Native AI is the **investable vehicle** and is not valued as an application company.

It is valued as an **infrastructure-grade epistemic substrate**, applicable across AI governance, healthcare, environmental systems, capital allocation, and public institutions, wherever intelligent autonomous systems operate under pressure and require verifiable orientation before action.

Its value derives from enabling the **governance of intelligent systems at scale**, rather than from feature velocity or short-term growth.

This pre-seed round:

* prices custodial responsibility early,

* avoids premature dilution, and

* aligns capital with long-arc infrastructure emergence rather than application-layer optimisation.

### 

### **This Round**

This is a **custodial alignment round**, not a proof-of-concept round.

Investors are underwriting:

* posture,  
* sequencing,  
* and governance integrity under pressure.

The outcome of this round is not scale, it is **trustworthy infrastructure**.

## **8\. Structural Separation**

Field-Native AI is the **investable vehicle**.  
Inverse exists to **hold custody over posture, governance, and capital deployment constraints**.

This separation is structural, not advisory, and is designed to prevent the collapse of epistemic integrity under capital or execution pressure.

### 

### **Custodial Role of Inverse**

Inverse holds custodial responsibility for:

* preservation of epistemic posture,  
* enforcement of refusal and gating constraints, and  
* stewardship of capital sequencing across phases.

Inverse does **not**:

* operate Field-Native AI as a product company,  
* direct day-to-day technical execution, or  
* optimise for growth, performance, or market capture.

Its authority is limited to ensuring that Field-Native AI does not violate the conditions required for orientation-first intelligence to remain coherent under pressure.

### **Role of Field-Native AI**

Field-Native AI is responsible for:

* development and operation of the technology infrastructure,  
* implementation of Triangulated Entailment IP and action-gating mechanisms,  
* deployment of Phase I products and pilots, and  
* execution within constraints held upstream.

Field-Native AI does **not**:

* override custodial constraints,  
* collapse implication into action for the sake of optimisation, or  
* expand beyond demonstrated responsibility.

### **Intellectual Property**

Core intellectual property, including:

* Triangulated Entailment,  
* entailment surface computation,  
* refusal and gating architectures, and  
* orientation-first system primitives

is held within Field-Native AI, subject to custodial and authorship constraints stewarded by Inverse.

Licensing, transfer, or externalisation of this IP is constrained by governance mechanisms that preserve epistemic integrity across all phases.

### **Capital Flow and Control**

Capital raised in this round is invested into **Field-Native AI**.

Deployment of capital is constrained by:

* phase-gated milestones,  
* explicit failure conditions, and  
* custodial oversight that prevents premature expansion or acceleration.

Capital does not purchase authority over execution.  
It participates subject to demonstrated readiness at each infrastructural threshold.

### **Governance Boundary**

This separation ensures that:

* capital cannot force execution,  
* execution cannot override posture, and  
* posture remains accountable without becoming operational.

Custody is exercised as **constraint**, not command.

This structure allows Field-Native AI to accumulate trust, responsibility, and dependency over time without compromising the conditions that make it viable as infrastructure.

## **Why This Matters**

The primary risk to orientation-first intelligence is not technical failure, but **structural collapse under pressure**.

By separating custody, capital, and execution, Field-Native AI is able to:

* progress only when responsibility is earned,  
* refuse action without penalty, and  
* remain governable even as capability increases.

This separation is not a control mechanism.  
It is the precondition for infrastructure-grade legitimacy.

## **9\. Competition & Landscape**

Field-Native AI does not enter a crowded product category.  
It occupies a **structural gap** that existing systems cannot fill without violating their own design assumptions.

Rather than competing on capability, speed, or adoption, Field-Native AI sits **upstream of execution**, where orientation, implication, and responsibility must be made explicit before action.

### **Intelligence-as-Execution Platforms**

Representative example: **Palantir**

These platforms excel at:

* integrating heterogeneous data at scale,  
* supporting high-stakes operational decisions,  
* accelerating execution in complex environments.

They are structurally optimised for **action under pressure**.

However, they assume that:

* the frame of decision is already valid,  
* authority is implicit in the system,  
* and optimisation toward action is desirable.

They do not surface:

* where implication is incomplete,  
* where contradiction remains unresolved,  
* or where non-action is the correct outcome.

Field-Native AI does not replace these systems.  
It provides the **epistemic conditions under which their outputs can be used legitimately**.

The relationship is complementary, not competitive.

### **AI Governance, Safety, and Monitoring Tooling**

This category includes:

* alignment layers,  
* monitoring and observability tools,  
* policy enforcement and compliance systems.

These tools operate **downstream of model behaviour**.

They:

* observe outputs,  
* flag anomalies,  
* and attempt to constrain behaviour after decisions have already been formed.

They do not intervene at the level of:

* implication,  
* frame declaration,  
* or derivability before execution.

Field-Native AI operates **before behaviour exists**, restoring orientation rather than correcting outcomes.

### **Knowledge Graphs, Ontologies, and Semantic Systems**

These systems provide:

* structured representations of information,  
* schema-based reasoning,  
* and consistency enforcement.

They assume:

* stable ontologies,  
* eventual convergence,  
* and resolution of contradiction through schema alignment.

Field-Native AI makes a different assumption:

* contradiction is signal,  
* boundary is first-class,  
* and divergence may persist without collapse.

As a result, Field-Native AI can operate in contexts where schema stability is neither available nor desirable.

### **Foundation Models and Frontier AI Labs**

Parametric models are powerful generators of language, hypotheses, and pattern recognition.

When treated as authorities, they:

* internalise assumptions invisibly,  
* collapse uncertainty into fluency,  
* and obscure provenance.

Field-Native AI does not compete with these models.

It **repositions them**:

* as proposal generators,  
* as translators,  
* and as expressive tools,

LLM’s fill space with assumptions about what is true relative to what is known. Field-Native AI surfaces what is already implicitly true within the space to make the truth explicit.

### 

### **Structural Summary**

Across all categories, existing systems are optimised for at least one of:

* speed,  
* scale,  
* optimisation,  
* or decisiveness.

Field-Native AI is optimised for **none** of these.

It is optimised for:

* preserving implication,  
* making boundary explicit,  
* and ensuring that action remains legitimate under pressure.

This is why Field-Native AI does not displace existing platforms. Instead it **constrains the conditions under which they may be used**.

### **Implication**

The absence of direct competitors is not a claim of superiority, it is a consequence of occupying the implication space, which sits upstream of inference, and has historically remained implicit.

As autonomous systems proliferate, this layer becomes unavoidable to prevent scaling inadvertent harm.

Field-Native AI is seeking to **stabilise a neglected function that can no longer be left undefined**.

## **10\. Risk & Structural Mitigations**

Field-Native AI is designed for contexts where failure is costly and ambiguity cannot be hidden. Accordingly, the principal risks are not ignored or minimised. They are made explicit and addressed **structurally**, rather than through aspiration or policy.

### **Risk: Incentive Misalignment and Adoption Resistance**

Some organisations may resist orientation-first governance due to incentives that prioritise speed, capability expansion, or optimisation over epistemic integrity.

This is not treated as an anomaly.  
It is an expected feature of the current AI landscape.

**Structural Mitigation**

Field-Native AI is architected to be:

* model-agnostic,  
* independent of any single provider,  
* and capable of enforcing epistemic constraints at the point of execution rather than persuasion.

The system does not require universal adoption to function.  
It remains viable wherever execution can be gated.

### **Risk: Perceived Latency and Action Friction**

Systems that refuse premature action may be perceived as slow or obstructive, particularly in cultures habituated to rapid execution.

**Structural Mitigation**

Latency is treated as an **epistemic signal**, not a performance defect.

Field-Native AI makes explicit when:

* implication is still unfolding,  
* contradiction remains unresolved,  
* or additional constraint would materially change outcomes.

This reframes delay as risk prevention rather than inefficiency.

### **Risk: Capture by High-Power Actors**

Any system that governs execution under pressure may attract attempts at capture, acceleration, or coercive use.

**Structural Mitigation**

Custodial separation is maintained between:

* IP authorship (PowerHouse)  
* capital stewardship (Inverse),  
* technology execution (Field-Native AI),  
* and downstream application.

Additionally:

* action gating is enforced architecturally, not by policy,  
* refusal pathways are explicit and auditable,  
* and no single actor can override entailment constraints without violating system integrity.

### **Risk: Founder and Custodial Centrality**

Early-stage custodial posture is currently concentrated.

**Structural Mitigation**

Custody is treated as a **transmissible structure**, not a personal trait.

Mitigations include:

* explicit documentation of refusal constraints and epistemic posture,  
* early formation of a custodial council,  
* and governance mechanisms that encode constraint rather than discretion.

### **Risk: Market Education and Category Novelty**

The category of orientation-first intelligence infrastructure is not yet widely recognised.

**Structural Mitigation**

Field-Native AI does not rely on conceptual adoption.

It demonstrates value through:

* refusal events,  
* auditability under pressure,  
* and the prevention of irreversible action.

Understanding follows exposure, not explanation.

### **Risk: Overextension Before Infrastructure Readiness**

Premature expansion across domains risks diluting custodial integrity.

**Structural Mitigation**

Growth is constrained by:

* custodial throughput,  
* domain readiness,  
* and the system’s capacity to preserve implication without collapse.

Expansion is treated as a consequence of coherence, not a goal.

## **Summary**

The dominant risks facing Field-Native AI arise not from technical uncertainty, but from **power dynamics, incentive misalignment, and premature acceleration**.

Each is addressed not through optimism or enforcement, but through **architectural refusal, custodial separation, and explicit constraint**.

This approach does not eliminate risk.  
It ensures that risk remains **visible, bounded, and governable**.

## **11\. Pre-Seed Round: Capital Structure & Use of Funds**

This pre-seed round is structured to align capital with **custodial responsibility**, not acceleration.

It is designed to fund the initial emergence of Field-Native AI as an infrastructure-grade substrate while preserving the structural conditions required for epistemic integrity under pressure.

### **Capital Structure**

* **Investable Vehicle:** Field-Native AI  
* **Round Type:** Pre-Seed  
* **Capital Requirement:** USD $2.0M  
* **Pre-Money Valuation:** USD $40.0M  
* **Equity Issue:** 5.0%  
* **Post-Money Valuation:** USD $42.0M

This pricing reflects Field-Native AI’s position as an infrastructure-grade epistemic control point, stewarded under custodial constraints held upstream.

The round is intentionally limited in size to:

* preserve governance coherence,  
* avoid premature dilution,  
* and maintain alignment between capital and custodial throughput.

### **Use of Funds**

Capital raised in this round will be deployed exclusively toward **Phase I execution**, with explicit constraints on scope and acceleration.

Permitted uses include:

* Development of the Field-Native AI governance layer for AI agents  
* Implementation of entailment computation, boundary preservation, and action gating  
* Construction of auditability, provenance, and refusal pathways  
* Integration tooling for deployment alongside existing AI systems  
* Minimal operational support required to sustain integrity and continuity

Funds will not be used for:

* growth marketing or demand generation,  
* feature expansion beyond the Phase I wedge,  
* optimisation for speed or performance metrics,  
* or incentives that privilege execution over epistemic coherence.

### **Governance and Oversight**

Capital deployment is stewarded under custodial constraints that preserve separation between:

* capital and posture,  
* technology and execution,  
* orientation and optimisation.

Governance mechanisms ensure that:

* no action pathway bypasses entailment constraints,  
* no capital pressure forces premature expansion,  
* and refusal remains a valid and protected system outcome.

These constraints are structural, not discretionary.

### **Milestones for This Round**

The objective of this round is **proof of infrastructural validity**.

Success is measured by:

* operational action gating in live agent environments,  
* explicit refusal under real execution pressure,  
* preservation of provenance and boundary in audit scenarios,  
* and sustained coherence without collapse across multiple deployments.

These outcomes de-risk subsequent capital without requiring revenue-led validation.

### **Investor Alignment**

This round is intended for investors who:

* understand infrastructure emergence timelines,  
* are comfortable with constraint as a value driver,  
* and prefer long-arc integrity over short-term acceleration.

## **12\. Capital Phases, On-Ramps, and Off-Ramps**

Field-Native AI is structured to progress through **discrete infrastructural thresholds**, not continuous growth stages. Each capital phase corresponds to a clear shift in responsibility, capability, and risk profile.

Capital is invited to enter only where the system has demonstrated readiness to carry the implications of the next phase.

### **Pre-Seed (Current Round): Proof of Infrastructural Validity**

**Purpose**  
To demonstrate that orientation-first intelligence can govern execution **under real pressure** without collapse.

**Primary Objective**  
Establish *proof of infrastructural validity*.

**Key Milestones**

* Action gating operational in live AI agent environments  
* Explicit refusal events under execution pressure  
* Preservation of provenance, boundary, and contradiction in audit contexts  
* Successful deployment alongside existing AI systems without displacement

**What This Unlocks**

* Legitimacy of Field-Native AI as a governance substrate  
* Validation that non-action can be structurally enforced  
* Readiness to assume responsibility for deeper intelligence primitives

**Failure Conditions**

* If infrastructural validity cannot be demonstrated, expansion is halted.  
* The system does not proceed to model-building without this proof.

### **Seed Round: Foundation Model Construction**

**Purpose**  
To internalise epistemic authority by constructing a **foundation model governed by entailment**, rather than optimisation.

**Primary Objective**  
Demonstrate that a foundation model can operate **subordinate to implication**, not as an authority.

**Key Milestones**

* Development of a foundation model explicitly governed by Triangulated Entailment  
* Demonstrated separation between proposal (model output) and derivation (entailment)  
* Continued refusal and gating under increased capability  
* Stable operation without optimisation pressure collapse  
* Evidence of appreciating computation returns with scale

**What This Unlocks**

* Independence from incumbent adoption timelines  
* Full-stack epistemic integrity (from sensing to derivation to execution)  
* Readiness for cross-domain pilots without governance drift

**Failure Conditions**

* If foundation model authority cannot be structurally constrained, progression stops.  
* Capability is not allowed to outrun governance.

### **Series A: Pilot Expansion and Domain Translation**

**Purpose**  
To translate infrastructural capability into **bounded, high-stakes pilot programs** across select domains.

**Primary Objective**  
Demonstrate that the same epistemic substrate generalises **without change in principle**.

**Key Milestones**

* Successful pilots in 2–3 additional domains (e.g. healthcare, environment, capital systems)  
* Evidence of sustained coherence under heterogeneous pressure  
* External institutional reliance on orientation outputs  
* Initial standardisation of interfaces and deployment patterns

**What This Unlocks**

* Productisation of pilot learnings  
* Early institutional dependency  
* Readiness for infrastructure-scale deployment

**Failure Conditions**

* Expansion pauses if coherence degrades across domains.  
* Breadth does not override integrity.

### **Series B: Infrastructure Scaling and Technology Transfer**

**Purpose**  
To scale Field-Native AI as **shared infrastructure**, not as a centralised product.

**Primary Objective**  
Enable technology transfer, standardisation, and integration at civilisation scale.

**Key Milestones**

* Stable multi-domain operation with sustained trust accumulation  
* Standardised infrastructure interfaces for integration by third parties  
* Technology transfer frameworks that preserve epistemic constraints  
* Governance models that survive decentralised deployment

**What This Unlocks**

* Infrastructure-level dependency  
* Long-arc value capture without centralised control  
* Durability beyond founding team involvement

### **12\. Closing Orientation**

These phases are not an attempt to optimise valuation or momentum.

They establish the conditions under which Field-Native AI can emerge **without compromising the very properties that make it necessary**.

Capital is invited to participate where restraint, patience, and custodial alignment are understood as assets rather than liabilities.

# **13\. Appendix A: Market Scope & Economic Underwriting**

This appendix provides explicit market quantification and economic assumptions that underpin the valuation and capital structure described in the core memorandum.

It exists to support underwriting and internal diligence.  
It does not alter the posture, sequencing, or custodial constraints defined in the main document.

## **A1. Market Definition Logic**

The market for Field-Native AI is defined by **failure mode**, not by product category.

Specifically, the addressable market consists of systems in which:

* autonomous or semi-autonomous action occurs under pressure,  
* consequences are irreversible or high-cost,  
* and failure arises from lack of discernment rather than lack of capability.

This definition explicitly excludes:

* consumer productivity tools,  
* general-purpose SaaS,  
* low-stakes automation,  
* and optimisation-only decision support.

The market is therefore bounded by **responsibility-bearing systems**, not by total AI spend.

## **A2. Total Addressable Market (TAM)**

The TAM is constructed from sectors where epistemic failure produces systemic harm and where governance spend already exists or is emerging.

Indicative global annual spend (order-of-magnitude):

* AI governance, safety, and compliance (public \+ private):  
  \~$40–60B  
* Healthcare decision systems and clinical governance infrastructure:  
  \~$60–80B  
* Environmental monitoring, remediation, and regulatory systems:  
  \~$30–50B  
* Capital allocation, risk, and systemic financial governance:  
  \~$50–70B  
* Public sector and institutional decision infrastructure:  
  \~$40–60B

**Estimated TAM:**  
**$220–320B annually**

This figure reflects **governance and infrastructure spend**, not model training or consumer applications.

## **A3. Serviceable Available Market (SAM)**

The initial SAM is intentionally constrained to domains where:

* autonomous agents are already deployed or imminent,  
* regulatory or fiduciary accountability exists,  
* and refusal, auditability, and provenance are valued.

Initial SAM domains include:

* AI agent governance in regulated or high-risk environments,  
* clinical and critical-care decision contexts,  
* environmental remediation and monitoring pilots,  
* select institutional capital systems.

Estimated initial SAM:  
**$15–25B annually**

This reflects only markets accessible without domain re-architecture or policy reform.

## **A4. Serviceable Obtainable Market (SOM)**

The SOM is constrained not by demand, but by **custodial throughput**.

Field-Native AI intentionally limits early deployment to:

* a small number of institutions,  
* high-touch, high-stakes environments,  
* and pilots that stress epistemic integrity rather than scale.

Assumptions:

* Early institutional ACV: $1–5M per deployment  
* Initial deployments: 10–20 over medium term  
* Gradual expansion post-Series A

Estimated medium-term SOM capture:  
**1–2% of SAM**

This constraint is deliberate and protective.

## **A5. Economic Model and Value Capture**

Field-Native AI captures value through:

* infrastructure licensing,  
* governance-layer deployment,  
* and long-arc dependency rather than usage optimisation.

Value accrues through:

* avoidance of catastrophic failure,  
* reduction of downstream liability,  
* and institutional reliance on orientation outputs.

This is a **risk-cost substitution model**, not a volume-based SaaS model.

## **A6. Valuation Anchors**

The pre-seed valuation reflects:

* infrastructure-grade positioning,  
* civilisation-level applicability,  
* explicit phase gating and failure conditions,  
* and custodial constraints that reduce tail risk.

Comparable valuation logic draws from:

* infrastructure platforms rather than applications,  
* governance and risk systems rather than productivity tools,  
* and long-arc dependency rather than growth multiples.

The $40M pre-money valuation is coherent relative to:

* scope of responsibility assumed,  
* architectural novelty,  
* and disciplined capital sequencing.

## **A7. Sensitivities and Downside Scenarios**

Key sensitivities include:

* slower-than-expected institutional adoption,  
* resistance from incumbent systems,  
* and increased cost of custodial oversight.

Downside protection is provided through:

* phased capital deployment,  
* explicit failure conditions,  
* and the ability to halt expansion without collapse.

In downside scenarios, capital preservation is prioritised over growth.

## 

## 

## **15\. Glossary**

**Action Gating**  
A structural mechanism that prevents execution from occurring until predefined epistemic conditions are satisfied. Action is treated as optional and contingent, not assumed.

**Custody**  
The responsibility for holding posture, constraints, and sequencing upstream of execution. Custody operates through enforced limits rather than directive control.

**Discernment**  
The capacity to determine what is occurring, what follows from it, and whether action is warranted. Discernment precedes decision-making and execution.

**Entailment**  
The set of consequences that follow from a given frame, context, and set of conditions. Entailment makes implicit consequences explicit without collapsing uncertainty.

**Entailment Surface**  
A structured representation of implications across perspectives that preserves provenance, boundary, contradiction, and uncertainty.

**Epistemic Integrity**  
The condition in which a system’s outputs, actions, and decisions remain traceable to their originating frames, assumptions, and constraints.

**Field-Native AI**  
An orientation-first intelligence substrate designed to surface implication before action and to govern execution under pressure. Field-Native AI prioritises discernment over optimisation.

**Foundation Model (in this context)**  
A general-purpose model that is explicitly governed by entailment and action-gating constraints, operating subordinate to implication rather than as an authority.

**Governance Layer**  
An infrastructure layer that sits alongside existing AI systems to enforce orientation, refusal, auditability, and responsibility without replacing underlying models.

**Implication**  
The implicit truth that becomes visible when a system is correctly oriented within declared frames. Implication is the inverse of inference.

**Inference**  
A process that deduces explicit conclusions from incomplete information, often filling gaps through assumption or optimisation.

**Infrastructure-Grade**  
A system whose removal would cause systemic failure because it has become depended upon for orientation or operation.

**Orientation**  
The shared, verifiable capacity to sense reality in context before action. Orientation is a prerequisite for discernment and responsibility.

**Posture**  
The declared stance a system takes toward uncertainty, responsibility, and action. Posture constrains what a system is permitted to do.

**Refusal**  
A valid and enforceable outcome in which a system declines to act because epistemic conditions are not satisfied. Refusal is treated as capability, not failure.

**Sequencing**  
The ordered progression of capability, responsibility, and scale. Sequencing ensures that systems do not advance faster than their capacity to hold implication.

**Triangulated Entailment**  
A proprietary method for surfacing what is true across perspectives by resolving implication through multiple, constrained frames without collapsing uncertainty.

**Verifiable Orientation**  
Orientation that can be audited, traced, and agreed upon across observers prior to execution.

---

### **Usage Note**

These terms are defined narrowly for the purposes of this memorandum.  
They are operational definitions, not philosophical claims.

